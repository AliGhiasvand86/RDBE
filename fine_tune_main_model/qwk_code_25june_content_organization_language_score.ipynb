{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TTm-cF8jkRJg",
        "outputId": "b9a9391f-451d-455b-8b51-e45c8e7008d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "09ccc459bd4342feadf27949fba7750e",
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0A7TANUjF0g",
        "outputId": "0f96dcfd-9015-4b25-b7b7-cabdd03b7ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.0, 3.5, 3.5, 3.0, 4.5, 4.5, 3.0, 4.0, 4.0, 2.5, 3.5, 3.5, 4.0, 4.0, 4.0, 2.5, 3.0, 4.0, 3.5, 4.5, 4.0, 4.0, 3.5, 3.0, 2.5, 3.0, 4.0, 4.0, 3.5, 4.0, 4.5, 4.5, 3.0, 4.5, 2.0, 3.0, 4.5, 4.0, 4.0, 4.0, 3.5, 3.5, 4.0, 3.0, 4.5, 2.0, 3.5, 3.5, 2.0, 4.0, 2.5, 3.5, 4.5, 2.0, 3.0, 4.0, 3.0, 1.5, 4.0, 2.5, 3.5, 3.0, 4.0, 2.5, 3.0, 2.5, 2.5, 4.0, 2.5, 2.5, 3.5, 3.0, 4.5, 3.0, 2.5, 4.0, 4.0, 2.5, 3.5, 4.5, 3.0, 3.5, 4.0, 3.5, 2.5, 3.5, 3.5, 2.5, 3.5, 4.0, 4.5, 3.5, 3.0, 3.0, 3.5, 2.5, 3.0, 3.0, 3.5, 4.5, 4.0, 3.0, 3.0, 3.0, 4.0, 4.5, 4.5, 4.5, 2.0, 3.5, 3.0, 4.0, 4.0, 4.0, 2.0, 3.5, 3.5, 3.5, 2.0, 3.0, 4.0, 2.5, 3.0, 2.5, 3.5, 3.5, 4.0, 2.5, 4.0, 4.0, 3.5, 3.5, 3.0, 4.5, 3.0, 3.5, 4.5, 2.0, 4.0, 3.5, 3.0, 3.5, 3.5, 2.5, 3.0, 2.5, 3.5, 2.5, 3.5, 2.5, 4.0, 2.5, 4.0, 2.5, 2.5, 4.0, 3.5, 2.0, 4.0, 4.5, 2.5, 2.0, 2.5, 4.0, 2.5, 3.5, 3.5, 3.0, 2.5, 4.0, 2.5, 1.5, 4.5, 2.0, 2.0, 3.0, 4.0, 3.5, 4.5, 3.0, 3.0, 4.0, 3.0, 4.0, 3.5, 3.5, 4.0, 4.0, 2.5, 4.0, 2.5, 4.0, 2.5, 3.5, 3.5, 4.0, 3.5, 3.0, 3.0, 4.5, 3.5, 3.0, 4.5, 2.0, 3.0, 4.0, 3.5, 3.0, 4.5, 4.0, 3.0, 3.5, 3.0, 4.0, 3.5, 4.0, 4.0, 2.5, 2.5, 4.0, 3.0, 3.5, 4.0, 4.0, 3.5, 2.5, 3.0, 4.0, 4.0, 3.5, 3.5, 4.0, 4.5, 1.0, 4.5, 4.0, 4.0, 3.5, 3.5, 2.0, 4.0, 3.0, 4.0, 3.0, 3.5, 4.0, 3.0, 3.0, 2.5, 4.0, 3.5, 3.0, 3.5, 3.5, 3.5, 2.5, 3.0, 4.5, 3.5, 3.5, 2.0, 2.0, 3.5, 3.0, 3.5, 4.0, 3.0, 4.5, 4.0, 4.0, 1.5, 3.5, 2.5, 3.0, 3.5, 2.0, 4.0, 3.5, 4.0, 4.0, 4.0, 4.5, 3.0, 4.0, 4.0, 3.0, 4.0, 2.0, 4.5, 3.0, 3.0, 3.0, 2.5, 3.0, 3.5, 2.5, 3.5, 2.5, 4.0, 3.5, 3.0, 4.0, 3.0, 3.5, 3.5, 4.0, 2.5, 3.0, 3.5, 3.5, 4.5, 4.0, 3.0, 4.0, 3.5, 1.5, 3.5, 4.0, 1.5, 3.0, 3.0, 3.5, 3.5, 2.5, 3.5, 3.0, 4.0, 4.0, 3.5, 4.0, 3.5, 3.0, 3.5, 2.5, 2.5, 3.5, 3.0, 2.5, 4.0, 3.0, 3.0, 2.5, 3.5, 3.5, 2.5, 2.5, 3.5, 2.5, 4.0, 4.5, 4.0, 3.0, 2.0, 3.0, 3.5, 1.0, 3.5, 4.0, 3.0, 3.0, 2.0, 3.0, 2.5, 3.0, 3.0, 3.0, 4.5, 3.0, 2.5, 3.5, 3.5, 3.5, 3.0, 3.5, 4.0, 4.0, 3.5, 4.5, 2.0, 3.0, 3.5, 5.0, 3.0, 4.5, 3.5, 3.0, 3.5, 3.5, 3.0, 3.5, 3.5, 3.0, 1.5, 2.0, 3.5, 2.5]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('AliGhiasvand86/last_model_epoch15_24june_infernecetest_answers_without_best')\n",
        "df_inference = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/DREsS_LLAMA_Inference_v2_23june.csv')\n",
        "\n",
        "# Split data in 60:20:20 ratio\n",
        "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=22)\n",
        "test_df, val_df = train_test_split(temp_df, test_size=0.5, random_state=22)\n",
        "\n",
        "# Extract content scores from test_df\n",
        "content_scores = test_df['language'].tolist()\n",
        "\n",
        "# Display the content scores\n",
        "print(content_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdPrHVKPkAqJ",
        "outputId": "0e8801f0-6601-4175-f28d-481b49f53740"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "396"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(content_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4CbKejDmFO4",
        "outputId": "ba79c8b3-b13e-473f-be8a-9c201e2b3b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.5, 3.5, 3.5, 3.5, 4.0, 4.0, 3.5, 4.0, 4.0, 2.5, 3.5, 4.0, 4.0, 4.0, 4.0, 3.0, 3.5, 4.0, 4.0, 4.0, 3.0, 3.5, 4.0, 3.0, 3.5, 3.5, 4.0, 4.0, 4.0, 4.0, 4.5, 4.0, 3.5, 4.0, 2.5, 2.5, 4.0, 4.0, 3.5, 4.0, 4.0, 3.5, 4.5, 4.0, 4.5, 2.5, 3.0, 4.0, 3.5, 3.0, 2.5, 3.0, 4.0, 2.5, 3.0, 3.5, 2.5, 2.5, 4.0, 3.0, 3.5, 3.5, 4.0, 2.5, 4.0, 2.5, 2.5, 3.5, 2.5, 2.5, 4.0, 3.5, 4.0, 3.0, 2.5, 4.0, 4.0, 2.5, 3.0, 4.0, 4.0, 4.0, 4.0, 2.5, 2.5, 4.0, 3.5, 3.0, 2.5, 4.0, 4.0, 4.0, 3.0, 3.0, 3.5, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.5, 2.5, 4.0, 4.5, 4.5, 3.5, 3.5, 3.0, 3.0, 2.5, 4.0, 3.0, 2.5, 2.5, 4.0, 4.0, 3.0, 4.0, 3.5, 2.5, 3.5, 3.0, 3.0, 4.0, 2.5, 2.5, 3.0, 2.5, 4.0, 4.0, 2.5, 4.0, 4.0, 3.0, 4.5, 2.5, 4.0, 3.5, 3.0, 3.0, 3.5, 2.5, 2.5, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 4.0, 4.0, 3.5, 4.0, 3.5, 3.5, 4.5, 4.0, 2.5, 2.5, 2.5, 4.0, 2.5, 4.0, 4.0, 4.0, 2.5, 3.5, 3.5, 3.0, 4.0, 2.5, 3.0, 4.0, 4.0, 3.0, 3.5, 4.0, 3.0, 4.0, 3.0, 4.0, 3.5, 4.0, 4.0, 3.5, 3.0, 3.5, 2.5, 4.5, 3.0, 4.0, 4.0, 3.5, 3.5, 3.5, 3.5, 4.0, 4.0, 3.5, 4.5, 2.5, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 2.5, 4.0, 4.0, 4.0, 4.0, 4.5, 4.0, 3.0, 2.5, 4.0, 2.5, 3.5, 4.5, 4.0, 3.5, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.5, 4.0, 2.5, 4.5, 4.5, 3.0, 3.5, 3.0, 2.5, 4.0, 3.0, 4.0, 3.5, 2.5, 4.0, 2.5, 4.0, 3.0, 4.0, 4.0, 3.0, 2.5, 3.0, 3.0, 2.5, 3.0, 4.0, 4.0, 4.0, 2.5, 2.5, 4.0, 3.5, 4.0, 3.5, 2.5, 4.0, 4.0, 4.0, 2.5, 3.5, 3.5, 2.5, 2.5, 3.5, 4.0, 3.5, 3.5, 4.5, 4.0, 4.5, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 4.0, 2.5, 3.5, 3.5, 2.5, 2.5, 3.0, 3.5, 3.0, 4.0, 3.5, 2.5, 4.0, 3.5, 2.5, 2.5, 4.0, 4.5, 3.0, 3.5, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 2.5, 3.5, 4.0, 2.5, 4.0, 4.0, 4.0, 4.0, 2.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.5, 4.0, 3.5, 3.5, 2.5, 3.0, 4.0, 3.0, 2.5, 4.0, 3.5, 3.0, 2.5, 3.5, 3.0, 2.5, 3.0, 3.0, 3.0, 4.0, 4.5, 4.0, 2.5, 2.5, 3.5, 3.0, 2.5, 3.5, 4.0, 3.0, 3.0, 3.0, 2.5, 3.5, 3.5, 4.0, 2.5, 4.5, 3.0, 3.5, 3.0, 4.5, 3.5, 4.0, 2.5, 4.0, 4.5, 3.5, 4.5, 2.5, 3.5, 4.0, 4.0, 2.5, 4.0, 3.5, 3.0, 3.5, 4.0, 3.0, 3.5, 4.5, 3.0, 3.5, 2.5, 4.0, 4.0]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# فرض می‌کنیم df_inference دیتافریمی است که شامل داده‌های شما است\n",
        "# و ستون 'inputs' شامل جمله‌های مورد نظر است\n",
        "\n",
        "# تعریف لیستی برای ذخیره نمرات استخراج شده\n",
        "content_score_inference = []\n",
        "\n",
        "# تکرار بر روی تک تک ردیف‌های دیتافریم\n",
        "for index, row in df_inference.iterrows():\n",
        "    # گرفتن جمله از ستون 'inputs'\n",
        "    sentence = row[\"inputs\"]\n",
        "\n",
        "    # بررسی وجود عبارت \"Content\" در جمله\n",
        "    if \"[Scoring Rubric]\\nLanguage: \" in sentence:\n",
        "        # اسپلیت کردن جمله بر اساس '---> '\n",
        "        parts = row[\"outputs\"].split('---> ')\n",
        "\n",
        "        # گرفتن آخرین بخش و تبدیل آن به عدد صحیح\n",
        "        score = float(parts[-1].strip())\n",
        "\n",
        "        # اضافه کردن نمره به لیست\n",
        "        content_score_inference.append(score)\n",
        "\n",
        "# نمایش نمرات\n",
        "print(content_score_inference)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT3sA41AqtBH",
        "outputId": "fe1ccd8b-4b3a-416a-c72e-954419bd83f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "396"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(content_score_inference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "giinjQa_m04G",
        "outputId": "a61d8f8e-e948-4934-d5b1-1869beb609d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "396"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(content_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASoLr0PZnHGF",
        "outputId": "e2e574b3-c9ad-413f-b846-43c519d1ae1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed Content Scores: [6, 7, 7, 6, 9, 9, 6, 8, 8, 5, 7, 7, 8, 8, 8, 5, 6, 8, 7, 9, 8, 8, 7, 6, 5, 6, 8, 8, 7, 8, 9, 9, 6, 9, 4, 6, 9, 8, 8, 8, 7, 7, 8, 6, 9, 4, 7, 7, 4, 8, 5, 7, 9, 4, 6, 8, 6, 3, 8, 5, 7, 6, 8, 5, 6, 5, 5, 8, 5, 5, 7, 6, 9, 6, 5, 8, 8, 5, 7, 9, 6, 7, 8, 7, 5, 7, 7, 5, 7, 8, 9, 7, 6, 6, 7, 5, 6, 6, 7, 9, 8, 6, 6, 6, 8, 9, 9, 9, 4, 7, 6, 8, 8, 8, 4, 7, 7, 7, 4, 6, 8, 5, 6, 5, 7, 7, 8, 5, 8, 8, 7, 7, 6, 9, 6, 7, 9, 4, 8, 7, 6, 7, 7, 5, 6, 5, 7, 5, 7, 5, 8, 5, 8, 5, 5, 8, 7, 4, 8, 9, 5, 4, 5, 8, 5, 7, 7, 6, 5, 8, 5, 3, 9, 4, 4, 6, 8, 7, 9, 6, 6, 8, 6, 8, 7, 7, 8, 8, 5, 8, 5, 8, 5, 7, 7, 8, 7, 6, 6, 9, 7, 6, 9, 4, 6, 8, 7, 6, 9, 8, 6, 7, 6, 8, 7, 8, 8, 5, 5, 8, 6, 7, 8, 8, 7, 5, 6, 8, 8, 7, 7, 8, 9, 2, 9, 8, 8, 7, 7, 4, 8, 6, 8, 6, 7, 8, 6, 6, 5, 8, 7, 6, 7, 7, 7, 5, 6, 9, 7, 7, 4, 4, 7, 6, 7, 8, 6, 9, 8, 8, 3, 7, 5, 6, 7, 4, 8, 7, 8, 8, 8, 9, 6, 8, 8, 6, 8, 4, 9, 6, 6, 6, 5, 6, 7, 5, 7, 5, 8, 7, 6, 8, 6, 7, 7, 8, 5, 6, 7, 7, 9, 8, 6, 8, 7, 3, 7, 8, 3, 6, 6, 7, 7, 5, 7, 6, 8, 8, 7, 8, 7, 6, 7, 5, 5, 7, 6, 5, 8, 6, 6, 5, 7, 7, 5, 5, 7, 5, 8, 9, 8, 6, 4, 6, 7, 2, 7, 8, 6, 6, 4, 6, 5, 6, 6, 6, 9, 6, 5, 7, 7, 7, 6, 7, 8, 8, 7, 9, 4, 6, 7, 10, 6, 9, 7, 6, 7, 7, 6, 7, 7, 6, 3, 4, 7, 5]\n",
            "Transformed Content Score Inference: [7, 7, 7, 7, 8, 8, 7, 8, 8, 5, 7, 8, 8, 8, 8, 6, 7, 8, 8, 8, 6, 7, 8, 6, 7, 7, 8, 8, 8, 8, 9, 8, 7, 8, 5, 5, 8, 8, 7, 8, 8, 7, 9, 8, 9, 5, 6, 8, 7, 6, 5, 6, 8, 5, 6, 7, 5, 5, 8, 6, 7, 7, 8, 5, 8, 5, 5, 7, 5, 5, 8, 7, 8, 6, 5, 8, 8, 5, 6, 8, 8, 8, 8, 5, 5, 8, 7, 6, 5, 8, 8, 8, 6, 6, 7, 8, 6, 8, 8, 8, 8, 6, 7, 5, 8, 9, 9, 7, 7, 6, 6, 5, 8, 6, 5, 5, 8, 8, 6, 8, 7, 5, 7, 6, 6, 8, 5, 5, 6, 5, 8, 8, 5, 8, 8, 6, 9, 5, 8, 7, 6, 6, 7, 5, 5, 6, 6, 6, 8, 6, 8, 6, 8, 8, 7, 8, 7, 7, 9, 8, 5, 5, 5, 8, 5, 8, 8, 8, 5, 7, 7, 6, 8, 5, 6, 8, 8, 6, 7, 8, 6, 8, 6, 8, 7, 8, 8, 7, 6, 7, 5, 9, 6, 8, 8, 7, 7, 7, 7, 8, 8, 7, 9, 5, 8, 8, 8, 6, 8, 8, 5, 8, 8, 8, 8, 9, 8, 6, 5, 8, 5, 7, 9, 8, 7, 6, 6, 8, 8, 8, 8, 7, 8, 5, 9, 9, 6, 7, 6, 5, 8, 6, 8, 7, 5, 8, 5, 8, 6, 8, 8, 6, 5, 6, 6, 5, 6, 8, 8, 8, 5, 5, 8, 7, 8, 7, 5, 8, 8, 8, 5, 7, 7, 5, 5, 7, 8, 7, 7, 9, 8, 9, 8, 8, 8, 6, 8, 6, 8, 5, 7, 7, 5, 5, 6, 7, 6, 8, 7, 5, 8, 7, 5, 5, 8, 9, 6, 7, 8, 8, 8, 8, 6, 8, 8, 5, 7, 8, 5, 8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 9, 8, 7, 7, 5, 6, 8, 6, 5, 8, 7, 6, 5, 7, 6, 5, 6, 6, 6, 8, 9, 8, 5, 5, 7, 6, 5, 7, 8, 6, 6, 6, 5, 7, 7, 8, 5, 9, 6, 7, 6, 9, 7, 8, 5, 8, 9, 7, 9, 5, 7, 8, 8, 5, 8, 7, 6, 7, 8, 6, 7, 9, 6, 7, 5, 8, 8]\n"
          ]
        }
      ],
      "source": [
        "def transform_list_1(scores):\n",
        "    transformed_scores = []\n",
        "    for score in scores:\n",
        "        if score == 0:\n",
        "            transformed_scores.append(0)\n",
        "        elif score == 0.5:\n",
        "            transformed_scores.append(1)\n",
        "        elif score == 1:\n",
        "            transformed_scores.append(2)\n",
        "        elif score == 1.5:\n",
        "            transformed_scores.append(3)\n",
        "        elif score == 2:\n",
        "            transformed_scores.append(4)\n",
        "        elif score == 2.5:\n",
        "            transformed_scores.append(5)\n",
        "        elif score == 3:\n",
        "            transformed_scores.append(6)\n",
        "        elif score == 3.5:\n",
        "            transformed_scores.append(7)\n",
        "        elif score == 4:\n",
        "            transformed_scores.append(8)\n",
        "        elif score == 4.5:\n",
        "            transformed_scores.append(9)\n",
        "        elif score == 5:\n",
        "            transformed_scores.append(10)\n",
        "        else:\n",
        "            # Handle other cases if needed\n",
        "            pass\n",
        "    return transformed_scores\n",
        "\n",
        "def transform_list_2(scores):\n",
        "    transformed_scores = []\n",
        "    for score in scores:\n",
        "        if score == 0:\n",
        "            transformed_scores.append(0)\n",
        "        elif score == 0.5:\n",
        "            transformed_scores.append(1)\n",
        "        elif score == 1:\n",
        "            transformed_scores.append(2)\n",
        "        elif score == 1.5:\n",
        "            transformed_scores.append(3)\n",
        "        elif score == 2:\n",
        "            transformed_scores.append(4)\n",
        "        elif score == 2.5:\n",
        "            transformed_scores.append(5)\n",
        "        elif score == 3:\n",
        "            transformed_scores.append(6)\n",
        "        elif score == 3.5:\n",
        "            transformed_scores.append(7)\n",
        "        elif score == 4:\n",
        "            transformed_scores.append(8)\n",
        "        elif score == 4.5:\n",
        "            transformed_scores.append(9)\n",
        "        elif score == 5:\n",
        "            transformed_scores.append(10)\n",
        "        else:\n",
        "            # Handle other cases if needed\n",
        "            pass\n",
        "    return transformed_scores\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "\n",
        "transformed_scores_1 = transform_list_1(content_scores)\n",
        "transformed_scores_2 = transform_list_2(content_score_inference)\n",
        "\n",
        "print(\"Transformed Content Scores:\", transformed_scores_1)\n",
        "print(\"Transformed Content Score Inference:\", transformed_scores_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2Jb4JvqsraB",
        "outputId": "d0bc9b5b-757f-4329-9081-d5ba90ceb028"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "396"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(transformed_scores_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uO6ZgR9puZ3",
        "outputId": "ef423173-cb8c-41f9-f5cb-eb3b6806d4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QWK:  0.6386565514606557\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "print(\"QWK: \", cohen_kappa_score(transformed_scores_2, transformed_scores_1, weights=\"quadratic\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOG1tX60p2I-",
        "outputId": "20ec01cb-d61e-4c56-9220-c7ed13e6540d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "394"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(transformed_scores_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZsz55B_qF8Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
